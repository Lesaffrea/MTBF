---
title: "MTBF"
author: "Alain Lesaffrer"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
```{r init, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggeffects)
library(ggpubr)
library(janitor)
library(bootstrap)
output_data <-read.csv(stringr::str_c(here::here(),"/data/output.table.csv"), sep=",", skipNul = TRUE,fileEncoding="latin1" )
output_data  <-clean_names(output_data) %>%
                      dplyr::mutate( scheduled_start = lubridate::as_date(scheduled_start, format="%d/%m/%Y"))
output_data   <-output_data %>%
                      dplyr::filter( !row_number() %in% which(duplicated(output_data)))

```


## Summary

In this document, we explore the **MTBF** based on a data set from **Rio**. The main aim was about how to calculate the **MTBF**, which could be valid. 

In the second stage, we test small sample and check if we can build synthetic data set out of small sample.

## Overview

We show below the amount of failures for the devices. We check one material 40607997. 

```{r dsp_info,echo=FALSE}
process_data <-output_data %>%
                      dplyr::group_by(functional_location) %>%
                      dplyr::summarise( nb_failures = n(),
                                        start_date = min(scheduled_start),
                                        end_date   = max(scheduled_start))  %>%
                      dplyr::arrange( desc(nb_failures)) 
  
knitr::kable(process_data[1:15,])

one_material <- output_data %>%
                    dplyr::filter( functional_location =="3021BRC501C503ELEM.PULL.TAPU") %>%
                    dplyr::select(-material_description) %>%
                    dplyr::distinct() %>%
                    dplyr::arrange(scheduled_start )  %>%
                    dplyr::mutate( day_bet_failure = scheduled_start- lag(scheduled_start)) 
                

```

The distribution for the failure for the  floc **3021BRC501C503ELEM.PULL.TAPU** are as follow, we have a bimodal distribution here. One should be careful as the number of sample could be low, in case of *lagging* we have only few samples, therefor some enhancement such as *bootstrap* must be used. 

```{r dsp_dist,echo=FALSE, warning=FALSE, message=FALSE,fig.align="center"}
dsp_all <- ggplot(data=one_material) +
  geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
  theme_minimal() +
  labs(title="Floc 3021BRC501C503ELEM.PULL.TAPU", x="Days between failure")


dsp_bearing <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Bearing")) %>%
      ggplot(data=.) +
        geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
        theme_minimal() +
        labs(title="Floc bearing only ", x="Days between failure")

dsp_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging")) %>%
      ggplot(data=.) +
        geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
        theme_minimal() +
        labs(title="Lagging only ", x="Days between failure")


ggarrange( dsp_all, dsp_bearing, dsp_lagging)
```

# Boostrap 

We check now if we can enhanced the distribution using **bootstrap**, which will give use a family of of devices **mtbf**, the bootstrap is dome with 500 samples, in this case we can wonder about the zero occurrence in the rginal data set. We build the sample in this way:

1. Build a matrix with the number of days between failures as values

2. Do a bootstrap using sample with replacement with 500 samples 

```{r bootlagging, echo=FALSE}
all_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging"))
all_lagging_df <-t(as.data.frame.matrix(t(table(all_lagging$day_bet_failure))))
all_lagging_df <-as.data.frame.matrix(all_lagging_df)
all_lagging_df$values <-rownames(all_lagging_df)
all_boot <-list()
for( index in 1:20){
  all_boot[[index]] <-all_lagging_df$values[sample(nrow(all_lagging_df), 500, replace=TRUE)]
}
hist(as.numeric(all_boot[[16]]), main="Example of bootstrap", xlab = "Number days", col="lightblue")


```


We do the same bu we remove the zero day between failure from the data set. The lagging type has very few samples as shown below. 


```{r bootlagging_2, echo=FALSE}
all_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging")) %>%
    dplyr::filter( day_bet_failure > 0 )
all_lagging_df <-t(as.data.frame.matrix(t(table(all_lagging$day_bet_failure))))
all_lagging_df <-as.data.frame.matrix(all_lagging_df)
all_lagging_df$values <-rownames(all_lagging_df)

set.seed(123)
n <-length(unique(all_lagging$day_bet_failure))
theta <-function(x,df){ df$value[x]}
nb_sample <-100
bootsample <-bootstrap(1:n, nb_sample, theta, all_lagging_df)
result <-data.frame()
for( index in 1:nb_sample){
  tmp <-as.data.frame.table(table(bootsample$thetastar[,index]))
  if(nrow(result) == 0 ){
     result <- tmp
  }else{
    result <-result %>%
                     rbind(tmp)
  }  
}

result <-result %>%
            dplyr::group_by(Var1) %>%
            dplyr::summarise( total = sum(Freq))

```


|  Reference    | Value  |
|--------------|--------|
|  Number samples original | ```r nrow(all_lagging)``` |

After bootstrap for hundred samples, with zero excluded. We come to a uniform distribution as the seed was uniform. We come to similar samples as before. This method could be used to build a prior if we use Bayes type of statistics. 

```{r boostrap_small, echo=FALSE}
knitr::kable(result)
```

