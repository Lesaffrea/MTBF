---
title: "MTBF"
author: "Alain Lesaffrer"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
```{r init, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(janitor)
library(boot)
library(bootstrap)
library(modeest)
library(ggplot2)
library(ggeffects)
library(ggpubr)
library(WVPlots)
library(ggridges)
library(hrbrthemes)
library(gridExtra)
library(SPREDA)
source('./ReliabilitySupportFns.R')
output_data <-read.csv(stringr::str_c(here::here(),"/data/output.table.csv"), sep=",", skipNul = TRUE,fileEncoding="latin1" )
output_data  <-clean_names(output_data) %>%
                      dplyr::mutate( scheduled_start = lubridate::as_date(scheduled_start, format="%d/%m/%Y")) %>%
                      dplyr::filter( order_type == "PM01")
output_data   <-output_data %>%
                      dplyr::filter( !row_number() %in% which(duplicated(output_data)))

```


## Summary

In this document, we explore the **MTBF** based on a data set from **Rio**. The main aim was about how to calculate the **MTBF**, which could be valid, that do we take the standard formula $$\frac{delta \space time}{number \space incidents}$$ or do we calculate a distribution of independent per days, the difference is significant in our case from about 20 days to 40 days, we calculate the CI as well which is small, it means the MTBF under rate the number of days between failure.

To build this document, the **SKF** document **Bearing damage and failure analysis** has been  used. 

 For information the bearings failures, which are exceptional as most bearings live longer that the device they are associated with. 
 
 |  Type of failures for bearings |
 |--------------------------------|
 |  1/3 fatigue                   |
 |  1/3 lubrication problems      |
 |  1/6 contaminants              |
 |  1/6 others                    |
 
 
 Before to go further the definition of the MTBF is worst to mentioned, it is the number of failures to repair in a period of time, it is an arithmetic mean, so nothing to do with distribution as mentioned in this document.  Its meaning is therefore restricted as we show below the difference between the distribution calculation and the MTBF is important. 
 
 We do two calculations for two functional locations concerning the distribution MTBF, the distribution in this case are multomodal, the MTBF is taken as the lowest model of the distribution. 
 
 *One point**, it has been difficult to extract the distribution of failure in bearings, in this document we try but we have a uniform distribution, which make the calculation of **MTBF** nearly impossible. 
 
In the second stage, we test small sample and check if we can build synthetic data set out of small sample.

## Overview

We show below the amount of failures for the devices. We check one material 40607997. 

```{r dsp_info,echo=FALSE}
process_data <-output_data %>%
                      dplyr::group_by(functional_location) %>%
                      dplyr::summarise( nb_failures = n(),
                                        start_date = min(scheduled_start),
                                        end_date   = max(scheduled_start))  %>%
                      dplyr::arrange( desc(nb_failures)) 
  
knitr::kable(process_data[1:15,])

one_material <- output_data %>%
                    dplyr::filter( functional_location =="3021BRC501C503ELEM.PULL.TAPU") %>%
                    dplyr::distinct() %>%
                    dplyr::arrange(scheduled_start )  %>%
                    dplyr::mutate( day_bet_failure = scheduled_start- lag(scheduled_start)) 
                

```

The distribution for the failure for the  floc **3021BRC501C503ELEM.PULL.TAPU** are as follow, we have a bimodal distribution here. One should be careful as the number of sample could be low, in case of *lagging* we have only few samples, therefor some enhancement such as *bootstrap* must be used. 

```{r dsp_dist,echo=FALSE, warning=FALSE, message=FALSE,fig.align="center"}
dsp_all <- ggplot(data=one_material) +
  geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
  theme_minimal() +
  labs(title="Floc 3021BRC501C503ELEM.PULL.TAPU", x="Days between failure")


dsp_bearing <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Bearing")) %>%
      ggplot(data=.) +
        geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
        theme_minimal() +
        labs(title="Floc bearing only ", x="Days between failure")

dsp_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging")) %>%
      ggplot(data=.) +
        geom_density(aes(x=day_bet_failure), col="lightblue", fill="lightblue") +
        theme_minimal() +
        labs(title="Lagging only ", x="Days between failure")


ggarrange( dsp_all, dsp_bearing, dsp_lagging)
```

We show the bearing failure with different view, this distribution is close to poisson, which could be approximated. We have ``r sum(one_material$day_bet_failure == 0)``` samples with zero duration in this case, it represented 17% of the samples. 


```{r dsp_points, echo=FALSE}
hist(as.numeric(one_material$day_bet_failure), 
     col="lightblue", 
     xlab= "Number days",
     main="Floc 3021BRC501C503ELEM.PULL.TAPU") 

non_zero_failure = one_material$day_bet_failure[as.numeric(one_material$day_bet_failure) !=0]
```

The non zero distribution is as follow, 

```{r dsp_non_zaro, echo=FALSE}
hist(as.numeric(non_zero_failure), 
     col="lightblue", 
     xlab= "Number days",
     main="Floc 3021BRC501C503ELEM.PULL.TAPU") 
```

In the next lines we do a bootstrap on the number of days, we should not have a lot of difference with the orignal data as we have ```r nrow(one_material)``` samples. We calculate the confidence interval on the boostrap as we have a normal distribution in this case. The CI is pretty small. The following visual is a bootstrap of the subset and therefore give the standard deviation for the population. In this case the mean will be of 134 instead of 133 for the subset, which is closer to the mode as shown below. 

```{r dsp_Exp, echo=FALSE}
fact <- function( no ) {
# check if no negative, zero or one then return 1
if( no <= 1) {
    return(1)
  } else {
    return(no * fact(no-1))
  }
}

mean_time <- function(df,i){
  df <-df[i,]
  no_zero <-df$day_bet_failure[as.numeric(df$day_bet_failure) !=0]
  return( mean(no_zero) )
}

set.seed(89787)
one_material <- one_material[-1,]
boot_mean <-boot(one_material, mean_time, R= 1000)
boot_mean$t <-as.data.frame(boot_mean$t)
names(boot_mean$t) <-"mean"
PlotDistDensityNormal(boot_mean$t, 'mean', "Distribution mean boot") +
  theme_minimal()
mtbf<-round(((one_material$scheduled_start[19] - one_material$scheduled_start[1])/ nrow(one_material))[1],3)
delta_mtbf_dist <-mean(boot_mean$t$mean) -mtbf
```

If we do calculate the original MTBF for  the functional location we have a value of ```r round(((one_material$scheduled_start[19] - one_material$scheduled_start[1])/ nrow(one_material))[1],3)``` days. We have a difference of ```r as.numeric(delta_mtbf_dist)``` days if we take the bootstrap distribution rather than the mtbf as calculated with formula, this value has ne greatv. values as we are multimodal. 

The margin of error for the bootstrap mean is small and less than 1, to be exact ```r (sd(boot_mean$t$mean)/sqrt(1000))*1.96``` for 95% or Z score at 1.96. This CI bring us in the range of the sample which is close to the population it seems. 

## Checking by material 

The following visual shows the distribution of time between failaure, we can notice the first modes are similar. The material 07187 has a long time betwwen failure at the extrem, using the calculated MTBF will therefore have a values lot higher that the first mode. 

```{r metrail_mtbf, echo=FALSE, message=FALSE}
functional_3016 <- one_material |>
                        dplyr::group_by( material_description ) |>
                        dplyr::arrange(scheduled_start )  |>
                        dplyr::mutate( day_bet_failure  = ifelse( is.na(day_bet_failure),0, day_bet_failure)) |>
                        dplyr::filter( day_bet_failure > 0) |>
                        dplyr::arrange( material_description, by_group = TRUE) 


mode_functional_3016 <- functional_3016 |>
                                dplyr::summarise( mode = list(mlv(day_bet_failure, method = "meanshift")),
                                                  mtbf = sum(day_bet_failure)/ n())

ggplot( data = functional_3016, aes(x= day_bet_failure, y= material_description,  color= material_description, fill= material_description)) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none")

tmp_observe.dat <- functional_3016 |>  
                        dplyr::rename( time= day_bet_failure) |> 
                        dplyr::mutate(event =1) |> 
                        # dplyr::mutate( event = ifelse(time >500, 0 , event)) |>
                        dplyr::ungroup() |>
                        dplyr::select( event, time) |>
                        dplyr::mutate( time =as.integer(time))
```

For both material the time to failure is as follow, with no right censure. 

```{r dsptime, echo=FALSE}
Plot.Observations(tmp_observe.dat)
```



As we can see with the second material the difference between MTBF and mode is large, too large. 

| Material  |  Distribution MTBF |  MTBF |
|-----------|--------------------|-------|
| ```r mode_functional_3016$material_description[1]``` | ```r round(mode_functional_3016$mode[[1]][1],2)``` | ```r round(mode_functional_3016$mtbf[1],2) ```|
| ```r mode_functional_3016$material_description[2]``` | ```r round(mode_functional_3016$mode[[2]][1],2)``` | ```r round(mode_functional_3016$mtbf[2],2) ```|

In case of the first material, we could cenored the extrem, and then do a calculation with Weibull, which will give us the reliability that we can transform in MTBF. 

The **weibull* distribution is usually used in reliability, the method is different than the expectation for MTBF. We build a molde with both materail in this case. 


```{r weibull_model, echo=FALSE}
weinbull_mle <- Lifedata.MLE(Surv(time,event)~1,
                             data=tmp_observe.dat,
                             dist="weibull")
beta_mle <- 1 / unname(exp(weinbull_mle$coef[2]))
eta_mle  <- unname(exp(weinbull_mle$coef[1]))

beta.95cl_hi <- 1 / (summary(weinbull_mle)$coefmat["sigma","95% Lower"])
beta.95cl_lo <- 1 / (summary(weinbull_mle)$coefmat["sigma","95% Upper"])
eta.95cl_lo <- exp(summary(weinbull_mle)$coefmat["(Intercept)","95% Lower"])
eta.95cl_hi <- exp(summary(weinbull_mle)$coefmat["(Intercept)","95% Upper"])
```

The parameters for the **wienbull** is as follow, we use a 95% CI. 

|  Parameter            |  Low       | Value    |  High  |
|-----------------------|------------|----------|--------|
| Beta                  | ```r beta.95cl_lo``` | ```r beta_mle``` |  ```r beta.95cl_hi``` |
| Eta                   | ```r eta.95cl_lo```  | ```r eta_mle```  |  ```r eta.95cl_hi```  |


# Other functional location 

In th previous paragraph we use one functional location, in this section we use **3074REC1PCONVELEM .BELT**, in this function location we have more than 50 failures. In this case we deal only with pulley.

```{r functional, echo=FALSE}
functional_3074 <-output_data |> dplyr::filter( functional_location == "3074REC1PCONVELEM .BELT") |>
                                 dplyr::filter( stringr::str_length(material_description) > 0) |>
                                 # dplyr::mutate( material_description = factor(material_description)) |>
                                 dplyr::group_by(material_description) |>
                                 dplyr::arrange(scheduled_start )  |>
                                 dplyr::mutate( day_bet_failure = scheduled_start- lag(scheduled_start)) |>
                                 dplyr::mutate( day_bet_failure  = ifelse( is.na(day_bet_failure),0, day_bet_failure))
functional_3074 <- functional_3074 |> 
                                dplyr::arrange( material_description, by_group = TRUE) |>
                                dplyr::filter( day_bet_failure > 0)
```

The first pulleys description is as below, we can see that we deal with multiple pulleys *(Four)*, which make the analysis interesting and the time between faulre could be long, taking all the pulley we have a bimodal distribution.  

```{r pulley_dec, echo=FALSE}
knitr::kable(functional_3074$material_description[1])
```

We show the time between failure for the four pulleys, we can notice that some failures are close to each other. We make the assumption that it is not a planned maintenance, what is surpring is the no failure between 200 and 300 days. 

```{r dsp_pulley_graph, echo=FALSE, message=FALSE}
dsp_point <-ggplot( data = functional_3074, aes(x= scheduled_start, y= day_bet_failure, group= material_description, color= material_description)) +
        geom_point( ) +
        geom_jitter() +
        theme_ipsum() 

dsp_density <- ggplot( data = functional_3074, aes(x= day_bet_failure, y= material_description,  color= material_description, fill= material_description)) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none")
        
grid.arrange(dsp_point, dsp_density, 
             ncol = 1, nrow = 2)

# we calculate the mode, the datset is lareday group by matterail_description 
mode_functional_3074 <- functional_3074 |>
                                dplyr::summarise( mode = list(mlv(day_bet_failure, method = "meanshift")),
                                                  mtbf = sum(day_bet_failure)/ n())


```

If we use the MTBF formula which is challenging as we have period longer than a year. we have 2,75 failues per year. To build the distribution we have to consider the bimodal distribution, knowing that we have lower probability at 350 days. 

If we take the mode of distribution as the inspection time we have the following values, we can notice that the MTBF is higher than the mode MTBF, with 40 days difference, this could be an issue if we want to avoid the failure. 

| Material  |  Distribution MTBF |  MTBF |
|-----------|--------------------|-------|
| ```r mode_functional_3074$material_description[1]``` | ```r round(mode_functional_3074$mode[[1]][1],2)``` | ```r round(mode_functional_3074$mtbf[1],2) ```|
| ```r mode_functional_3074$material_description[2]``` | ```r round(mode_functional_3074$mode[[2]][1],2)``` | ```r round(mode_functional_3074$mtbf[2],2) ```|
| ```r mode_functional_3074$material_description[3]``` | ```r round(mode_functional_3074$mode[[3]][1],2)``` | ```r round(mode_functional_3074$mtbf[3],2) ```|
| ```r mode_functional_3074$material_description[4]``` | ```r round(mode_functional_3074$mode[[4]][1],2) ``` | ```r round(mode_functional_3074$mtbf[4],2) ```|



# Seond Boostrap 

We check now if we can enhanced the distribution using **bootstrap**, which will give use a family of devices **mtbf**, the bootstrap is done with 500 samples, in this case we can wonder about the zero occurrence in the original data set. We can notice that the shape of the **bootstrap** is different from the original. 

We build the sample in this way:

1. Build a matrix with the number of days between failures as values.

2. Do a bootstrap using sample with replacement with 500 samples. 

```{r bootlagging, echo=FALSE}
all_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging"))
all_lagging_df <-t(as.data.frame.matrix(t(table(all_lagging$day_bet_failure))))
all_lagging_df <-as.data.frame.matrix(all_lagging_df)
all_lagging_df$values <-rownames(all_lagging_df)
all_boot <-list()
for( index in 1:20){
  all_boot[[index]] <-all_lagging_df$values[sample(nrow(all_lagging_df), 500, replace=TRUE)]
}
hist(as.numeric(all_boot[[16]]), main="Example of bootstrap", xlab = "Number days", col="lightblue")

all_bearing <- one_material %>% dplyr::filter( stringr::str_detect(simplified_failure_mode, "Bearing"))
```


We do the same but we remove the zero day between failure from the data set. The lagging type has very few samples as shown below. 


```{r bootlagging_2, echo=FALSE}
all_lagging <- one_material %>%
    dplyr::filter( stringr::str_detect(simplified_failure_mode, "Lagging")) %>%
    dplyr::filter( day_bet_failure > 0 )
all_lagging_df <-t(as.data.frame.matrix(t(table(all_lagging$day_bet_failure))))
all_lagging_df <-as.data.frame.matrix(all_lagging_df)
all_lagging_df$values <-rownames(all_lagging_df)

set.seed(123)
n <-length(unique(all_lagging$day_bet_failure))
theta <-function(x,df){ df$value[x]}
nb_sample <-1000
bootsample <-bootstrap(1:n, nb_sample, theta, all_lagging_df)

result <-data.frame()
for( index in 1:nb_sample){
  tmp <-as.data.frame.table(table(bootsample$thetastar[,index]))
  if(nrow(result) == 0 ){
     result <- tmp
  }else{
    result <-result %>%
                     rbind(tmp)
  }  
}

result <-result %>%
            dplyr::group_by(Var1) %>%
            dplyr::summarise( total = sum(Freq))

```


|  Reference    | Value  |
|--------------|--------|
|  Number samples original | ```r nrow(all_lagging)``` |

After bootstrap for thousand samples, with zero excluded. We come to a nearly uniform distribution as the seed was uniform. We come to similar samples as before. We calculate the distance between the **Bootstrap** and the original and we have about .1 distance. This method could be used to build a prior if we use Bayes type of statistics. 

```{r boostrap_small, echo=FALSE}
results_tst <- result %>% 
                      dplyr::mutate( normalized= total / sum(total),
                                     scaled = normalized * nrow(result))
distance_boot <- sqrt(sum((results_tst$scaled-1)^2))

knitr::kable(result)
```

Distance of **bootstrap** sample with original ```r round(distance_boot,4)```.


# Bearings 

In this section we focus on the **bearing**, for which we have a bigger sample. As before we have a  uniform distribution. We show below the distribution with a window of twenty days, we have a range from one to three hundred and twenty days.

In the following table we can notice we work with intermittent tome series,  the mode is about 100 days and a second period at about 200 days. In both case the period is small less than a year, for the 100 days we shall check the type the cause of the replacement. 

```{r bearings_calc, echo=FALSE}
all_bearing <- one_material %>% dplyr::filter( stringr::str_detect(simplified_failure_mode, "Bearing"))
# bin twnenty 
table_20<-table(cut(as.numeric(attributes(table(all_bearing$day_bet_failure))$dimnames[[1]]), seq(0,350, 20)))

knitr::kable(table_20)
```
The data set is the following, we can see that this sample is over four years, therefore we must have some replacements already in this sample. 

```{r dsp_bearing, echo=FALSE}
skimr::skim(all_bearing %>% dplyr::select( day_bet_failure, scheduled_start ))

```

## Analsyis of the 100 days

We have five bearing in the period 80 to 120 days, based on this little sample we have *race bearing defect* as a recurring cause

```{r 100_days_analysis, echo=FALSE}
bearing_100 <- all_bearing %>%
                    dplyr::filter(day_bet_failure > 80 & day_bet_failure < 120 )

knitr::kable( bearing_100$failure_mode)

all_race  <- all_bearing %>% 
                     dplyr::filter( stringr::str_detect(failure_mode, "race"))
```


Out of all the bearing failure we have ```r nrow(all_race)``` with race problem or one quater of the failure encounter with bearing.  
